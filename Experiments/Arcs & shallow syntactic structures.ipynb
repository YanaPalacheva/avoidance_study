{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convokit's Arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from convokit import Corpus \n",
    "\n",
    "CORP_PATH = os.path.dirname(os.getcwd())+'\\\\Corpora\\\\'\n",
    "\n",
    "# corpus_all = Corpus(CORP_PATH+'full-avoidance-corpus')\n",
    "corpus_avoidance = Corpus(CORP_PATH+'avoidance-corpus')\n",
    "# corpus_non_avoidance = Corpus(CORP_PATH+'non-avoidance-corpus')\n",
    "# corpus_fight = Corpus(CORP_PATH+'fight-corpus')\n",
    "# corpus_flight = Corpus(CORP_PATH+'flight-corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit.text_processing import TextProcessor\n",
    "from nltk.corpus import stopwords\n",
    "# STOPWORDS = stopwords.words(\"english\")\n",
    "STOPWORDS = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", \n",
    "                 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', \n",
    "                 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', \n",
    "                 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', \n",
    "                 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'or', \n",
    "                 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'between', 'into', 'through', \n",
    "                 'during', 'before', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', \n",
    "                 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', \n",
    "                 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 's', 'will', 'just', 'should', 'll', 'm', 'o', \n",
    "                 're', 'y', 'ma', 'hon']\n",
    "\n",
    "class RemoveStopWords(TextProcessor):\n",
    "\t\"\"\"\n",
    "\t\tTransformer \n",
    "\t\t:param output_field: name of attribute to output to.\n",
    "\t\t:param input_field: name of field to use as input. defaults to 'parsed', which stores dependency parses as returned by the TextParser transformer; otherwise expects similarly-formatted input.\n",
    "\t\t:param input_filter: a boolean function of signature `input_filter(utterance, aux_input)`. parses will only be computed for utterances where `input_filter` returns `True`. By default, will always return `True`, meaning that arcs will be computed for all utterances.\n",
    "\t\t:param verbosity: frequency of status messages.\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self, output_field, input_field='parsed', input_filter=None, verbosity=0):\n",
    "\t\tTextProcessor.__init__(self, censor_stopwords, \n",
    "\t\t\toutput_field=output_field, input_field=input_field,\n",
    "\t\t\tinput_filter=input_filter, verbosity=verbosity)\n",
    "\n",
    "def _is_stopword(tok):\n",
    "\treturn tok['tok'].lower() in STOPWORDS\n",
    "\n",
    "def _convert_stopword(tok, sent):\n",
    "\tif _is_stopword(tok):\n",
    "# \t\thas_w = _get_w_det(tok, sent)\n",
    "# \t\tif has_w:\n",
    "# \t\t\treturn has_w.lower()\n",
    "# \t\telse:\n",
    "\t\treturn 'STOPWORD'\n",
    "\treturn tok['tok'].lower()\n",
    "\n",
    "def censor_stopwords(text_entry):\n",
    "\t\"\"\"\n",
    "\t\tStand-alone function that removes stopwords from parsed text.\n",
    "\t\t:param text_entry: parsed text\n",
    "\t\t:return: parse with stopwords censored out.\n",
    "\t\"\"\"\n",
    "\n",
    "\tsents = []\n",
    "\tfor raw_sent in text_entry:\n",
    "\t\tsent = {'rt': raw_sent['rt'], 'toks': []}\n",
    "\t\tfor raw_tok in raw_sent['toks']:\n",
    "\t\t\ttok = {k: raw_tok[k] for k in ['dep','dn','tag']}\n",
    "\t\t\tif 'up' in raw_tok: tok['up'] = raw_tok['up']\n",
    "\t\t\ttok['tok'] = _convert_stopword(raw_tok, raw_sent)\n",
    "\t\t\tsent['toks'].append(tok)\n",
    "\t\tsents.append(sent)\n",
    "\treturn sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 utterances processed\n",
      "100/346 utterances processed\n",
      "200/346 utterances processed\n",
      "300/346 utterances processed\n",
      "346/346 utterances processed\n",
      "100/346 utterances processed\n",
      "200/346 utterances processed\n",
      "300/346 utterances processed\n",
      "346/346 utterances processed\n"
     ]
    }
   ],
   "source": [
    "from convokit import TextParser\n",
    "\n",
    "parser = TextParser(verbosity=1000)\n",
    "corpus = parser.transform(corpus_avoidance)\n",
    "\n",
    "remove_stopwords = RemoveStopWords('parsed_cleaned', input_field='parsed', verbosity=100)\n",
    "corpus = remove_stopwords.transform(corpus)\n",
    "\n",
    "from convokit.text_processing import TextToArcs\n",
    "\n",
    "get_cleaned_arcs = TextToArcs('arcs_cleaned', input_field='parsed_cleaned', verbosity=100)\n",
    "corpus = get_cleaned_arcs.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('if>*', 11),\n",
       " ('but>*', 10),\n",
       " (\"gentleman_'s\", 10),\n",
       " (\"friend_'s\", 10),\n",
       " ('ireland_northern', 9),\n",
       " ('authorities_local', 8),\n",
       " ('however>*', 6),\n",
       " ('nations_united', 6),\n",
       " ('right_absolutely', 6),\n",
       " ('kingdom_united', 5),\n",
       " ('year_last', 5),\n",
       " (\"'s_not\", 5),\n",
       " ('deal_great', 5),\n",
       " ('union_european', 5),\n",
       " ('no>*', 4),\n",
       " ('friend_right', 4),\n",
       " ('make_can', 4),\n",
       " ('party_labour', 4),\n",
       " ('gave_ago', 4),\n",
       " ('much_very', 4),\n",
       " ('point_important', 4),\n",
       " (\"government_'s\", 4),\n",
       " ('assure_can', 4),\n",
       " ('service_health', 4),\n",
       " ('service_national', 4),\n",
       " ('states_united', 4),\n",
       " ('party_conservative', 4),\n",
       " ('minister_prime', 3),\n",
       " ('people_young', 3),\n",
       " ('ago_years', 3),\n",
       " ('system_voucher', 3),\n",
       " ('make_statement', 3),\n",
       " ('after>*', 3),\n",
       " ('yes>*', 3),\n",
       " ('thank_friend', 3),\n",
       " ('like>*', 3),\n",
       " ('yeah>*', 3),\n",
       " ('people_many', 3),\n",
       " ('ago_moments', 3),\n",
       " ('reply_gave', 3),\n",
       " ('year_next', 3),\n",
       " ('council_city', 3),\n",
       " ('government_labour', 3),\n",
       " ('one>*', 3),\n",
       " ('made_clear', 3),\n",
       " ('week_last', 3),\n",
       " ('destruction_mass', 3),\n",
       " ('hussein_saddam', 3),\n",
       " ('everyone>*', 3),\n",
       " ('years_past', 3),\n",
       " ('people_local', 3),\n",
       " ('benchers_front', 3),\n",
       " ('important_really', 3),\n",
       " ('important_extremely', 3),\n",
       " ('know_not', 3),\n",
       " (\"'s_mean\", 3),\n",
       " ('elected_democratically', 3),\n",
       " ('time_average', 3),\n",
       " ('royce_rolls', 3),\n",
       " ('point_friend', 3),\n",
       " ('deal_new', 3),\n",
       " ('part_important', 3),\n",
       " ('point_first', 3),\n",
       " ('see_can', 3),\n",
       " ('government_local', 3),\n",
       " ('work_further', 3),\n",
       " ('gentleman_right', 3),\n",
       " ('east_north', 3),\n",
       " ('least_not', 2),\n",
       " ('remind_friend', 2),\n",
       " ('years_two', 2),\n",
       " ('many>*', 2),\n",
       " ('councils_research', 2),\n",
       " ('principle_haldane', 2),\n",
       " ('years_many', 2),\n",
       " ('council_research', 2),\n",
       " ('made_proposals', 2),\n",
       " ('accept_not', 2),\n",
       " ('made_available', 2),\n",
       " ('well>*', 2),\n",
       " ('consider_shall', 2),\n",
       " ('work_ensure', 2),\n",
       " ('ago_weeks', 2),\n",
       " ('said_like', 2),\n",
       " (\"'s_yeah\", 2),\n",
       " ('difference_big', 2),\n",
       " ('make_difference', 2),\n",
       " ('recent_most', 2),\n",
       " ('say_can', 2),\n",
       " ('refer_gentleman', 2),\n",
       " ('council_leicester', 2),\n",
       " ('million_another', 2),\n",
       " ('million_year', 2),\n",
       " ('controlled_labour', 2),\n",
       " ('make_point', 2),\n",
       " ('move_towards', 2),\n",
       " ('sites_authorised', 2),\n",
       " ('played_better', 2),\n",
       " ('makes_point', 2),\n",
       " ('made_not', 2)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_arc_list = []\n",
    "for utt in corpus.iter_utterances():\n",
    "    if utt.reply_to:\n",
    "        arcs = utt.retrieve_meta('arcs_cleaned')\n",
    "        spl_arcs = [arc.split(' ') for arc in arcs]\n",
    "        for arc in spl_arcs:\n",
    "            for subarc in arc:\n",
    "                if 'stopword' not in subarc  and '_*' not in subarc:\n",
    "                    global_arc_list.append(subarc)\n",
    "\n",
    "from collections import Counter\n",
    "freq = Counter(global_arc_list)\n",
    "freq.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_sose)",
   "language": "python",
   "name": "ml_sose"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
