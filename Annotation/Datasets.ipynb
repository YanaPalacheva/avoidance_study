{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from convokit import Corpus, download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parliament corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at C:\\Users\\polin\\.convokit\\downloads\\parliament-corpus\n"
     ]
    }
   ],
   "source": [
    "# Download corpus and get dataframe\n",
    "parliament_corpus = Corpus(filename=download(\"parliament-corpus\"))\n",
    "parliament_us = parliament_corpus.get_utterances_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meta.pair_idx</th>\n",
       "      <th>text_q</th>\n",
       "      <th>id_q</th>\n",
       "      <th>text_a</th>\n",
       "      <th>id_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1979-05-21.0.0</td>\n",
       "      <td>asked the Secretary of State for Trade if it i...</td>\n",
       "      <td>1979-05-21a.669.13</td>\n",
       "      <td>Does my right hon Friend think that it is a co...</td>\n",
       "      <td>1979-05-21a.670.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1979-05-21.1.0</td>\n",
       "      <td>In 1978 , the United Kingdom had a visible tra...</td>\n",
       "      <td>1979-05-21a.672.3</td>\n",
       "      <td>Does my hon Friend agree that the trading defi...</td>\n",
       "      <td>1979-05-21a.673.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    meta.pair_idx                                             text_q  \\\n",
       "0  1979-05-21.0.0  asked the Secretary of State for Trade if it i...   \n",
       "1  1979-05-21.1.0  In 1978 , the United Kingdom had a visible tra...   \n",
       "\n",
       "                 id_q                                             text_a  \\\n",
       "0  1979-05-21a.669.13  Does my right hon Friend think that it is a co...   \n",
       "1   1979-05-21a.672.3  Does my hon Friend agree that the trading defi...   \n",
       "\n",
       "                id_a  \n",
       "0  1979-05-21a.670.2  \n",
       "1  1979-05-21a.673.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get useful columns\n",
    "parliament_us = parliament_us[['text', 'meta.is_question', 'meta.is_answer', 'meta.pair_idx']]\n",
    "parliament_us['idx'] = parliament_us.index\n",
    "\n",
    "# Get dfs for Qs and As\n",
    "parliament_q = parliament_us.groupby('meta.pair_idx').nth(0).reset_index()\n",
    "parliament_a = parliament_us.groupby('meta.pair_idx').nth(1).reset_index()\n",
    "\n",
    "# Merge dfs into one df for QA-pairs\n",
    "parliament_qa = pd.concat([parliament_q.reset_index(), parliament_a.drop('meta.pair_idx', 1)], axis=1)\n",
    "parliament_qa = parliament_qa.drop(['index', 'meta.is_question', 'meta.is_answer'], axis=1)\n",
    "parliament_qa = parliament_qa.dropna()\n",
    "parliament_qa.columns = ['meta.pair_idx', 'text_q', 'id_q', 'text_a', 'id_a']\n",
    "parliament_qa.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216893, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parliament_qa.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tennis corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at C:\\Users\\polin\\.convokit\\downloads\\tennis-corpus\n"
     ]
    }
   ],
   "source": [
    "# Download corpus and get dataframe\n",
    "tennis_corpus = Corpus(filename=download(\"tennis-corpus\"))\n",
    "tennis_us = tennis_corpus.get_utterances_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meta.pair_idx</th>\n",
       "      <th>text_q</th>\n",
       "      <th>id_q</th>\n",
       "      <th>text_a</th>\n",
       "      <th>id_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0_0</td>\n",
       "      <td>That last set seemed like a faultless performa...</td>\n",
       "      <td>0_0.q</td>\n",
       "      <td>Yeah, I served extremely well, and then the tw...</td>\n",
       "      <td>0_0.a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0_1</td>\n",
       "      <td>Did playing the semifinal, finishing that off ...</td>\n",
       "      <td>0_1.q</td>\n",
       "      <td>No, I don't think so. You know, it was an unfo...</td>\n",
       "      <td>0_1.a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  meta.pair_idx                                             text_q   id_q  \\\n",
       "0           0_0  That last set seemed like a faultless performa...  0_0.q   \n",
       "1           0_1  Did playing the semifinal, finishing that off ...  0_1.q   \n",
       "\n",
       "                                              text_a   id_a  \n",
       "0  Yeah, I served extremely well, and then the tw...  0_0.a  \n",
       "1  No, I don't think so. You know, it was an unfo...  0_1.a  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get useful columns\n",
    "tennis_us = tennis_us[['text', 'meta.is_question', 'meta.is_answer', 'meta.pair_idx']]\n",
    "tennis_us['idx'] = tennis_us.index\n",
    "\n",
    "# Get dfs for Qs and As\n",
    "tennis_q = tennis_us.groupby('meta.pair_idx').nth(0).reset_index()\n",
    "tennis_a = tennis_us.groupby('meta.pair_idx').nth(1).reset_index()\n",
    "\n",
    "# Merge dfs into one df for QA-pairs\n",
    "tennis_qa = pd.concat([tennis_q, tennis_a.drop('meta.pair_idx', 1)], axis=1)\n",
    "tennis_qa = tennis_qa.drop(['meta.is_question', 'meta.is_answer'], axis=1)\n",
    "tennis_qa = tennis_qa.dropna()\n",
    "tennis_qa.columns = ['meta.pair_idx', 'text_q', 'id_q', 'text_a', 'id_a']\n",
    "tennis_qa.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81974, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tennis_qa.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit Coarse Discourse corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at C:\\Users\\polin\\.convokit\\downloads\\reddit-coarse-discourse-corpus\n"
     ]
    }
   ],
   "source": [
    "# Download corpus and get dataframe\n",
    "coarse_corpus = Corpus(filename=download(\"reddit-coarse-discourse-corpus\"))\n",
    "coarse_us = coarse_corpus.get_utterances_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_q</th>\n",
       "      <th>id_q</th>\n",
       "      <th>text_a</th>\n",
       "      <th>id_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I can't find them anywhere! I just want the mo...</td>\n",
       "      <td>t3_16h61h</td>\n",
       "      <td>I saw several new ones yesterday, including a ...</td>\n",
       "      <td>t1_c7w4iik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>I can't find them anywhere! I just want the mo...</td>\n",
       "      <td>t3_16h61h</td>\n",
       "      <td>lots of pawn shops around me, Augusta GA, have...</td>\n",
       "      <td>t1_c7w8hlf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_q       id_q  \\\n",
       "0  I can't find them anywhere! I just want the mo...  t3_16h61h   \n",
       "1  I can't find them anywhere! I just want the mo...  t3_16h61h   \n",
       "\n",
       "                                              text_a        id_a  \n",
       "0  I saw several new ones yesterday, including a ...  t1_c7w4iik  \n",
       "1  lots of pawn shops around me, Augusta GA, have...  t1_c7w8hlf  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get useful columns\n",
    "coarse_us = coarse_us[['text', 'meta.majority_type', 'meta.majority_link']]\n",
    "coarse_us['idx'] = coarse_us.index\n",
    "\n",
    "# Get dfs for Qs and As\n",
    "coarse_q = coarse_us[coarse_us['meta.majority_type'] == 'question']\n",
    "coarse_a = coarse_us[coarse_us['meta.majority_type'] == 'answer']\n",
    "\n",
    "# Merge dfs into one df for QA-pairs\n",
    "coarse_qa = pd.merge(coarse_q, coarse_a, left_on='id', right_on='meta.majority_link', how='inner')\n",
    "coarse_qa = coarse_qa.drop(['meta.majority_type_x', 'meta.majority_link_x', 'meta.majority_type_y', 'meta.majority_link_y'], axis=1)\n",
    "coarse_qa.columns = ['text_q', 'id_q', 'text_a', 'id_a']\n",
    "coarse_qa.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39749, 4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coarse_qa.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Conversations Gone Awry corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at C:\\Users\\polin\\.convokit\\downloads\\conversations-gone-awry-corpus\n"
     ]
    }
   ],
   "source": [
    "# Download corpus and get dataframe\n",
    "awry_corpus = Corpus(filename=download(\"conversations-gone-awry-corpus\"))\n",
    "awry_us = awry_corpus.get_utterances_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_q</th>\n",
       "      <th>id_q</th>\n",
       "      <th>text_a</th>\n",
       "      <th>id_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Please stop removing and altering other editor...</td>\n",
       "      <td>144643838.1260.1236</td>\n",
       "      <td>Bullshit. I am correcting a simple mistake. I...</td>\n",
       "      <td>144645449.1479.1479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>But it certainly blows holes in the argument b...</td>\n",
       "      <td>68188977.25580.25580</td>\n",
       "      <td>Get a grip Ron.  First you confuse Iran and Ir...</td>\n",
       "      <td>68254097.25708.25708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_q                  id_q  \\\n",
       "0  Please stop removing and altering other editor...   144643838.1260.1236   \n",
       "1  But it certainly blows holes in the argument b...  68188977.25580.25580   \n",
       "\n",
       "                                              text_a                  id_a  \n",
       "0   Bullshit. I am correcting a simple mistake. I...   144645449.1479.1479  \n",
       "1  Get a grip Ron.  First you confuse Iran and Ir...  68254097.25708.25708  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop section headers\n",
    "awry_us = awry_us[awry_us['meta.is_section_header'] == False]\n",
    "\n",
    "# Get useful columns\n",
    "awry_us = awry_us[['text', 'reply_to', 'meta.comment_has_personal_attack']]\n",
    "awry_us['idx'] = awry_us.index\n",
    "\n",
    "# Get dfs for candidate As\n",
    "# Hypothesis: If a comment has a personal attack and replies to a Q, it could be A avoiding the Q.\n",
    "awry_a = awry_us[awry_us['meta.comment_has_personal_attack']]\n",
    "\n",
    "# Merge dfs into one df for QA-pairs\n",
    "awry_qa = pd.merge(awry_us, awry_a, left_on='id', right_on='reply_to', how='inner')\n",
    "awry_qa = awry_qa.drop(['reply_to_x', 'meta.comment_has_personal_attack_x', 'reply_to_y', 'meta.comment_has_personal_attack_y'], axis=1)\n",
    "awry_qa.columns = ['text_q', 'id_q', 'text_a', 'id_a']\n",
    "awry_qa.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1493, 4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awry_qa.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create samples from each dataset\n",
    "parliament_sample = parliament_qa.sample(n=200, random_state=1)\n",
    "tennis_sample = tennis_qa.sample(n=150, random_state=1)\n",
    "coarse_sample = coarse_qa.sample(n=150, random_state=1)\n",
    "\n",
    "# Add dataset identification\n",
    "parliament_sample['dataset'] = 'PQTC'\n",
    "tennis_sample['dataset'] = 'TI'\n",
    "coarse_sample['dataset'] = 'CDC'\n",
    "\n",
    "# Append data into one dataset and shuffle\n",
    "dataset = parliament_sample.append(tennis_sample, ignore_index = True).append(coarse_sample, ignore_index = True)\n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('question_avoidance_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
